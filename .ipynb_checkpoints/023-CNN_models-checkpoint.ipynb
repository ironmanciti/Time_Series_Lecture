{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate CNN Model\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)        # CNN 은 3 dimension input 이므로 axis 추가\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "window_size = 3\n",
    "batch_size = 1\n",
    "dataset = windowed_dataset(raw_seq, window_size, batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10]\n",
      "  [20]\n",
      "  [30]]] [[40]]\n",
      "[[[20]\n",
      "  [30]\n",
      "  [40]]] [[50]]\n",
      "[[[30]\n",
      "  [40]\n",
      "  [50]]] [[60]]\n",
      "[[[40]\n",
      "  [50]\n",
      "  [60]]] [[70]]\n",
      "[[[50]\n",
      "  [60]\n",
      "  [70]]] [[80]]\n",
      "[[[60]\n",
      "  [70]\n",
      "  [80]]] [[90]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17ca33aeb00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=[window_size, 1]),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model.fit(dataset, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99.77549]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.array([70, 80, 90])\n",
    "\n",
    "yhat = model.predict(x_input[:window_size].reshape(1, window_size, 1))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  45,  65,  85, 105, 125, 145, 165, 185])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert to [rows, columns] structure and horizontally stack the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq1 = in_seq1.reshape(-1, 1)\n",
    "in_seq2 = in_seq2.reshape(-1, 1)\n",
    "out_seq = out_seq.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)        # CNN 은 3 dimension input 이므로 axis 추가\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 2), (None,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.expand_dims(dataset, axis=1)\n",
    "ds = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "ds = ds.map(lambda window: (window[:window_size, 0:2], window[-1][-1]))\n",
    "ds = ds.batch(batch_size).prefetch(1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]] [65]\n",
      "[[[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]] [85]\n",
      "[[[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]] [105]\n",
      "[[[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]] [125]\n",
      "[[[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]] [145]\n",
      "[[[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]] [165]\n",
      "[[[70 75]\n",
      "  [80 85]\n",
      "  [90 95]]] [185]\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds:\n",
    "    print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17db2be73c8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=[window_size, 2]),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model.fit(ds, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 80,  85],\n",
       "        [ 90,  96],\n",
       "        [100, 105]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.array([[80, 85], [90, 96], [100, 105]])\n",
    "x_input = x_input.reshape((1, 3, 2))\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[205.09007]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
