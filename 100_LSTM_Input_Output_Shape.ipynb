{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Forecasting Input / Output Shape\n",
    "\n",
    "###  Univariate(단변수) Multi-step Input LSTM and Single-step Output\n",
    "이 모델은 단변수 시계열 데이터에 대한 LSTM을 사용하여 여러 타임 스텝의 입력을 기반으로 단일 타임 스텝의 출력을 생성합니다. 단변수 시계열 데이터란 하나의 특성만을 가진 데이터를 의미합니다. 여기서, 모델은 과거의 일정한 시간 윈도우(window) 내 데이터를 사용하여 미래의 한 단계 값을 예측합니다. 예를 들어, 과거 30일 동안의 주식 가격을 기반으로 내일의 주식 가격을 예측할 수 있습니다.\n",
    "\n",
    "### Multivariate(다변수) Multi-step Input LSTM and Single-step Output\n",
    "이 모델은 다변수 시계열 데이터에 대한 LSTM을 사용하여 여러 타임 스텝의 입력을 기반으로 단일 타임 스텝의 출력을 생성합니다. 다변수 시계열 데이터란 여러 개의 특성을 가진 데이터를 의미합니다. 이 모델은 단변수 버전과 비슷하지만, 여러 특성을 사용하여 예측을 수행합니다. 예를 들어, 주식 시장에서 과거 30일 동안의 주가, 거래량, 시가총액 등의 정보를 사용하여 내일의 주식 가격을 예측할 수 있습니다.\n",
    "\n",
    "여기서 **multi-step size**란 **window size**를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Univariate Multi-step Input and Single-step output LSTM \n",
    "\n",
    "- 단일변수 multi-timestep 입력 단일 timestep 출력  \n",
    "\n",
    "- input feature - 1, output unit - 1\n",
    "\n",
    "    ex) 과거 3 일간 종가 입력 $\\rightarrow$ 내일 주가 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_ds(series, window_size, batch_size, shuffle_buffer):    \n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size+1))\n",
    "    ds = ds.map(lambda window: (window[:-1], window[-1]))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trimu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "window_size = 3\n",
    "batch_size = 1\n",
    "dataset = windowed_ds(raw_seq, window_size, batch_size, 10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3) (1,)\n",
      "[[10 20 30]]\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(x.numpy().shape, y.numpy().shape)\n",
    "    print(x.numpy())\n",
    "    print(y.numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.LSTM(50, activation='relu', input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train이 안된 상태에서 간단히 모델을 작동시켜 입출력의 shape을 확인해 봅니다. 훈련이 안된 상태이므로 당연히 yhat 값은 의미가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n",
      "(1, 3, 1) (1, 1)\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]] [[11.35783]]\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([[70, 80, 90]])\n",
    "x_input = x_input.reshape(1, -1, 1)\n",
    "yhat = model.predict(x_input[:window_size])\n",
    "\n",
    "print(x_input.shape, yhat.shape)\n",
    "print(x_input, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multivariate Multi-step Input and Single-step Output LSTM \n",
    "\n",
    "- 여러개의 변수를 multi-timestep 입력 $\\rightarrow$ 단일 time-step 출력  \n",
    "\n",
    "- input feature - n, output unit - 1\n",
    "\n",
    "    ex) 주가, 환율 과거 3 일치 입력하여 다음날 주가(환율) 예측\n",
    "    ```\n",
    "    [[ 10,  15],\n",
    "     [ 20,  25],\n",
    "     [ 30,  35]]   --> [40]   \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input sequence 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_stock = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_forex = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "\n",
    "out_seq = in_stock[3:]\n",
    "out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[row, columns]` 구조로 변환하고 열을 수평으로 쌓습니다.\n",
    "\n",
    "여기서 in_stock과 in_forex 두 배열을 각각 2차원으로 변환하고, np.hstack() 함수를 사용하여 두 배열을 수평으로 연결합니다. 결과적으로 raw_seq는 두 배열을 나란히 놓은 형태의 2차원 배열이 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 15],\n",
       "       [20, 25],\n",
       "       [30, 35],\n",
       "       [40, 45],\n",
       "       [50, 55],\n",
       "       [60, 65],\n",
       "       [70, 75],\n",
       "       [80, 85],\n",
       "       [90, 95]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_stock = in_stock.reshape(-1, 1)\n",
    "in_forex = in_forex.reshape(-1, 1)\n",
    "\n",
    "raw_seq = np.hstack((in_stock, in_forex))\n",
    "raw_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds.map()을 사용하여 입력 특성과 레이블로 구성된 훈련 샘플을 생성합니다. 여기서 window[:-1]는 마지막 단계를 제외한 모든 단계의 모든 feature를 사용하여 입력 특성을 구성하고, window[-1, 0]는 마지막 단계의 첫 번째 feature(예: 주식 가격)을 레이블로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_ds(series, window_size, batch_size, shuffle_buffer):    \n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size+1))\n",
    "    ds = ds.map(lambda window: (window[:-1], window[-1, 0]))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 2), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 3\n",
    "batch_size = 1\n",
    "dataset = windowed_ds(raw_seq, window_size, batch_size, 10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2) (1,)\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]] [40]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(x.numpy().shape, y.numpy().shape)\n",
    "    print(x.numpy(), y.numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 50)                10600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,651\n",
      "Trainable params: 10,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.LSTM(50, activation='relu', input_shape=[None, 2]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "(1, 1, 2) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([[70, 80]])\n",
    "x_input = x_input.reshape(1, -1, 2)\n",
    "yhat = model.predict(x_input[:window_size])\n",
    "\n",
    "print(x_input.shape, yhat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다변수를 이용한 주가 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>24.565704</td>\n",
       "      <td>212818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>27.072500</td>\n",
       "      <td>27.162500</td>\n",
       "      <td>26.352501</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>23.873640</td>\n",
       "      <td>257142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>26.635000</td>\n",
       "      <td>26.857500</td>\n",
       "      <td>26.157499</td>\n",
       "      <td>26.565001</td>\n",
       "      <td>23.875891</td>\n",
       "      <td>263188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>26.799999</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>26.674999</td>\n",
       "      <td>26.937500</td>\n",
       "      <td>24.210680</td>\n",
       "      <td>160423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>27.307501</td>\n",
       "      <td>28.037500</td>\n",
       "      <td>27.174999</td>\n",
       "      <td>27.972500</td>\n",
       "      <td>25.140907</td>\n",
       "      <td>237458000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2015-01-02  27.847500  27.860001  26.837500  27.332500  24.565704  212818400\n",
       "2015-01-05  27.072500  27.162500  26.352501  26.562500  23.873640  257142000\n",
       "2015-01-06  26.635000  26.857500  26.157499  26.565001  23.875891  263188400\n",
       "2015-01-07  26.799999  27.049999  26.674999  26.937500  24.210680  160423600\n",
       "2015-01-08  27.307501  28.037500  27.174999  27.972500  25.140907  237458000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "df = yf.download('AAPL', start='2015-01-01', end='2019-12-31', progress=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.iloc[:, [3, 5]].values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2) (1,)\n",
      "\n",
      "[[[2.73325005e+01 2.12818400e+08]\n",
      "  [2.65625000e+01 2.57142000e+08]\n",
      "  [2.65650005e+01 2.63188400e+08]]] [26.9375]\n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "batch_size = 1\n",
    "\n",
    "ds = tf.expand_dims(dataset, axis=1)\n",
    "ds = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "ds = ds.window(window_size+1, shift=1, drop_remainder=True)\n",
    "ds = ds.flat_map(lambda w: w.batch(window_size+1))\n",
    "ds = ds.map(lambda w: (w[:-1], w[-1][0]))\n",
    "ds = ds.batch(batch_size).prefetch(1)\n",
    "ds\n",
    "\n",
    "for x, y in ds:\n",
    "    print(x.shape, y.shape)\n",
    "    print()\n",
    "    print(x.numpy(), y.numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
